# ILAIx

*An intelligent License evaluater*

![banner](docs/banner.png) <!-- optional: replace with your own banner or remove -->

---

## ğŸš€ Overview

ILAIx takes raw license texts (snippets, full files, SPDX headers, etc.) and predicts one or more internally defined license requirements using custom trained stateâ€‘ofâ€‘theâ€‘art transformer models (BERTâ€‘family, RoBERTa, ELECTRA). It then surfaces **why** each label was chosen via LIME, Integrated Gradients and sentenceâ€‘level importance ranking. A lightweight Flask web UI lets you explore predictions interactively.

### Highlights

* ğŸ“š Trained on **400+ SPDX licenses** evaluated (multiâ€‘label)
* ğŸ” Tokenâ€‘, sentenceâ€‘ and documentâ€‘level explanations (LIME & IG)
* ğŸ–¥ï¸ Minimal Flask + Tailwind frontâ€‘end for rapid demoing
* ğŸ§ª Reproducible training notebooks & dataâ€‘prep pipelines
* âš™ï¸ Dockerfile and GitHub Actions CI (optional, see below)

---

## ğŸƒâ€â™‚ï¸ Quick start

> **Prerequisites:** PythonÂ â‰¥3.10, (optional) CUDAâ€‘enabled GPU, GitÂ LFS.

```bash
# 1â€†.Â Clone the repo
$ git clone https://git.i.mercedes-benz.com/foss/ILAIx
$ cd ILAIx

# 2â€†.Â Create & activate environment (pick one)
$ conda env create -f environment.yml      # or:

# 3â€†.Â Launch the web UI
$ python ILAIx/main.py
# â†’ open http://127.0.0.1:5000 in your browser
```

---

## ğŸ—‚ï¸ Repository layout

| Path                                   | Purpose                                                                           |
| -------------------------------------- | --------------------------------------------------------------------------------- |
| `ILAIx/`                               | Flask Application with routes, templates, Tailwind static assets                  |
| `model/`                               | Preâ€‘trained checkpoints (**tracked with GitÂ LFS**)                                |
| `src/`                                 | Jupyter notebooks for data prep (`preprocessing/`), training (`training_new/`) and testing the checpoints (`loadTest/`) |

*(See the interactive table in the sideâ€‘panel for file counts & sizes.)*

---

## ğŸ§‘â€ğŸ’» Train your own model

1. Place raw license texts under `data/raw/` (one file per license sample).
2. Run `src/preprocessing/preprocess_spdx.ipynb` to generate tokenised datasets.
3. Open `src/training_new/modelTraining.ipynb`, pick your architecture & hyperâ€‘params, run all cells.

Tips

* Use the **DataAugmentation.ipynb** notebook to balance rare licenses.
* Integrated gradients require the modelâ€™s embeddings layer â€“ stick with HF models.

---

## ğŸ“œ License

<!-- TODO: choose one (MIT shown here) -->

This project is licensed under the **Mercedes-Benz Inner Source License 1.0 ("ISL")**. See [LICENSE](LICENSE) for details.

---

## âœï¸ Citation

If you use **ILAIx** in academic work, please cite:

```bibtex
@misc{ilaix_2025,
  title        = {ILAIx: An intelligent License evaluater},
  author       = {Nilesh Parshotam Rijhwani},
  year         = {2025},
  howpublished = {\url{https://git.i.mercedes-benz.com/foss/ILAIx}},
}
```

---

## ğŸ™‹â€â™€ï¸ Contributing

Pull requests are welcome! Please open an issue first to discuss major changes.

1. Fork the repo & create a branch: `git checkout -b feature/foo`
2. Commit your changes with clear messages
3. Run `pre-commit` and `pytest`
4. Submit a PR.

---

## ğŸ¤ Acknowledgements

* SPDX & ScanCode for open license datasets
* HuggingÂ Face Transformers ecosystem
* Captum & LIME for explainability libraries

---

> **Questions?** Open an issue or reach me at `rijhwaninilesh@gmail.com`.
