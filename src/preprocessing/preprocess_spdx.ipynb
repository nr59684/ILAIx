{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module provides a set of utility functions to clean text data, primarily intended for processing license text. The cleaning process involves three main steps:\n",
    "\n",
    "1.  **HTML Tag Removal:** The `remove_html_tags` function uses `BeautifulSoup` to parse HTML and extract the text content, effectively removing all HTML markup.\n",
    "2.  **Special Character Cleaning:** The `clean_special_chars` function uses regular expressions to remove any characters that are not alphanumeric, whitespace, or basic punctuation marks. This helps to standardize the text and remove potentially problematic characters.\n",
    "3.  **Whitespace Normalization:** The `normalize_whitespace` function ensures that there are no multiple spaces within the text and removes any leading or trailing whitespace. This ensures consistent spacing and formatting.\n",
    "\n",
    "The `preprocess_text` function combines these three steps into a single function, providing a convenient way to perform all cleaning operations at once. It returns an empty string if the input is None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"\n",
    "    Removes HTML tags from the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing HTML tags.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with HTML tags removed. Returns empty string if input is None.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text(separator=\" \")\n",
    "\n",
    "def clean_special_chars(text):\n",
    "    \"\"\"\n",
    "    Removes or replaces special characters from the given text.\n",
    "\n",
    "    This function removes characters that are not alphanumeric, whitespace, or basic punctuation.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing special characters.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with special characters removed. Returns empty string if input is None.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    # Remove characters that are not alphanumeric, whitespace, or basic punctuation\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Removes URLs starting with \"http\" or \"https\"\n",
    "\n",
    "    # Remove characters that are not alphanumeric, whitespace, or basic punctuation\n",
    "    cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s.,!?;:'\\\"-]\", \"\", text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    \"\"\"\n",
    "    Normalizes whitespace in the given text.\n",
    "\n",
    "    This function replaces multiple spaces with single spaces and removes leading/trailing whitespace.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text with potentially excessive whitespace.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with normalized whitespace. Returns empty string if input is None.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    cleaned_text = \" \".join(text.split())\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Combines all cleaning functions to process license text.\n",
    "\n",
    "    This function sequentially applies the following cleaning operations:\n",
    "    1. Removes HTML tags.\n",
    "    2. Removes special characters.\n",
    "    3. Normalizes whitespace.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input license text.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned license text. Returns empty string if input is None.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = remove_html_tags(text)\n",
    "    text = clean_special_chars(text)\n",
    "    text = normalize_whitespace(text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script preprocesses license text files from a specified input directory and saves the cleaned text to a designated output directory.\n",
    "\n",
    "The preprocessing steps involve:\n",
    "  1. Reading license text from .txt files in the input directory.\n",
    "  2. Calling the `preprocess_text` function to clean the text.\n",
    "  3. Saving the preprocessed text to a new file with the same name but appended with \"_preprocessed.txt\" in the output directory.\n",
    "\n",
    "The script creates the output directory if it doesn't exist to ensure proper file saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input directory containing the TXT files\n",
    "input_dir = \"../data/text\"  # Update with the correct path to your .txt files\n",
    "\n",
    "# Output directory to save the preprocessed licenses\n",
    "output_dir = \"../preprocessing/preprocessed_licenses_txt\"  # Update if needed\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through all TXT files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "\n",
    "        # Read the license text\n",
    "        with open(filepath, \"r\") as f:\n",
    "            license_text = f.read()\n",
    "\n",
    "        preprocessed_text = preprocess_text(license_text)\n",
    "\n",
    "        # Save the preprocessed text\n",
    "        output_filename = os.path.splitext(filename)[0] + \"_preprocessed.txt\"\n",
    "        output_filepath = os.path.join(output_dir, output_filename)\n",
    "\n",
    "        with open(output_filepath, \"w\") as outfile:\n",
    "            outfile.write(preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an additional script if we want to processes JSON files containing license information, extracts the license text, cleans it, and saves the cleaned text to individual text files.\n",
    "\n",
    "It iterates through JSON files in a specified input directory, extracts the value associated with the \"licenseText\" key, preprocesses this text using a `preprocess_text` function (assumed to be defined elsewhere), and saves the result as a .txt file in an output directory. The output filename is derived from the input JSON filename.\n",
    "\n",
    "The script also creates the output directory if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input directory containing the JSON files\n",
    "input_dir = \"../data/json/details\"  # Replace with the actual path\n",
    "\n",
    "# Output directory to save the cleaned licenses\n",
    "output_dir = \"../preprocessing/cleaned_licenses\"  # Replace with the actual path\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "\n",
    "        # Load the JSON file\n",
    "        with open(filepath, \"r\") as f:\n",
    "            license_data = json.load(f)\n",
    "\n",
    "        # Extract the license text\n",
    "        license_text = license_data.get(\"licenseText\", \"\")\n",
    "\n",
    "        # Clean the license text\n",
    "        cleaned_text = preprocess_text(license_text)\n",
    "\n",
    "        # Save the cleaned license text to a new file\n",
    "        output_filename = os.path.splitext(filename)[0] + \".txt\"  # e.g., Apache-2.0.txt\n",
    "        output_filepath = os.path.join(output_dir, output_filename)\n",
    "\n",
    "        with open(output_filepath, \"w\") as outfile:\n",
    "            outfile.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../../data/processed/preprocessed_licenses_json_2\"\n",
    "count=0\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "        # Read the license text\n",
    "        with open(filepath, \"r\") as f:\n",
    "            license_data=json.load(f)\n",
    "            if license_data['text']==\"\":\n",
    "                count+=1\n",
    "                print(license_data['name'])\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
