{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, hamming_loss, precision_recall_curve\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import nlpaug.augmenter.word as naw\n",
    "from nlpaug.util import Action\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 0. Choose Model: \"modernbert\", \"roberta\", or \"legalbert\"\n",
    "# ==================================================\n",
    "model_choice = \"legalbert\"  # change to \"legalbert\" or \"modernbert\" as desired\n",
    "\n",
    "if model_choice == \"roberta\":\n",
    "    model_name = \"roberta-base\"\n",
    "elif model_choice == \"legalbert\":\n",
    "    model_name = \"nlpaueb/legal-bert-base-uncased\"\n",
    "elif model_choice == \"modernbert\":\n",
    "    model_name = \"answerdotai/ModernBERT-base\"\n",
    "else:\n",
    "    raise ValueError(\"Invalid model_choice. Choose 'modernbert', 'roberta', or 'legalbert'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Load Data\n",
    "# -----------------------------\n",
    "def load_license_data(json_folder):\n",
    "    license_data = []\n",
    "    for filename in os.listdir(json_folder):\n",
    "        if filename.endswith(\".json\"):\n",
    "            license_name = filename[:-5]\n",
    "            filepath = os.path.join(json_folder, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                license_data.append({\n",
    "                    \"license_name\": license_name,\n",
    "                    \"family\": data[\"family\"],\n",
    "                    \"labels\": data[\"labels\"],\n",
    "                    \"text\": data[\"text\"],\n",
    "                })\n",
    "    return license_data\n",
    "\n",
    "json_folder = \"../../data/processed/preprocessed_licenses_json_2\"\n",
    "license_data = load_license_data(json_folder)\n",
    "df = pd.DataFrame(license_data)\n",
    "\n",
    "# Drop rows with missing labels\n",
    "df.dropna(subset=[\"labels\"], inplace=True)\n",
    "df = df[df[\"labels\"].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. Encode Labels\n",
    "# -----------------------------\n",
    "mlb = MultiLabelBinarizer()\n",
    "df[\"labels\"] = list(mlb.fit_transform(df[\"labels\"]))\n",
    "num_labels = len(mlb.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. Split Data\n",
    "# -----------------------------\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training size: 247\n",
      "Augmented training size: 972\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. BERT-Based Augmentation\n",
    "# -----------------------------\n",
    "\n",
    "def augment_text(text, aug_p=0.2, aug_max=3):\n",
    "    \"\"\"Context-aware augmentation using BERT\"\"\"\n",
    "    aug = naw.ContextualWordEmbsAug(\n",
    "        model_path='bert-base-uncased',\n",
    "        action=Action.SUBSTITUTE,\n",
    "        aug_p=aug_p,\n",
    "        aug_max=aug_max,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    return aug.augment(text)[0]  # Return first augmented version\n",
    "\n",
    "def augment_minority_classes(df, mlb, min_samples=50, aug_factor=3):\n",
    "    augmented_texts = []\n",
    "    augmented_labels = []\n",
    "    \n",
    "    # Calculate label counts (fixed)\n",
    "    label_matrix = np.array(df[\"labels\"].tolist())\n",
    "    label_counts = label_matrix.sum(axis=0)\n",
    "    minority_labels = np.where(label_counts < min_samples)[0]\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        labels = row[\"labels\"]\n",
    "        \n",
    "        # Check if sample contains minority labels\n",
    "        if any(label in minority_labels for label in np.where(labels == 1)[0]):\n",
    "            for _ in range(aug_factor):\n",
    "                new_text = augment_text(text)\n",
    "                augmented_texts.append(new_text)\n",
    "                augmented_labels.append(labels)\n",
    "    \n",
    "    # Create augmented DataFrame\n",
    "    augmented_df = pd.DataFrame({\n",
    "        \"text\": augmented_texts,\n",
    "        \"labels\": list(augmented_labels)\n",
    "    })\n",
    "    \n",
    "    return pd.concat([df, augmented_df], ignore_index=True)\n",
    "\n",
    "# Apply augmentation\n",
    "print(\"Original training size:\", len(train_df))\n",
    "train_df = augment_minority_classes(\n",
    "    train_df,\n",
    "    mlb=mlb,\n",
    "    min_samples=80,\n",
    "    aug_factor=5\n",
    ")\n",
    "print(\"Augmented training size:\", len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\NPARSHO\\.cache\\huggingface\\hub\\models--nlpaueb--legal-bert-base-uncased\\snapshots\\15b570cbf88259610b082a167dacc190124f60f6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\NPARSHO\\.cache\\huggingface\\hub\\models--nlpaueb--legal-bert-base-uncased\\snapshots\\15b570cbf88259610b082a167dacc190124f60f6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\NPARSHO\\.cache\\huggingface\\hub\\models--nlpaueb--legal-bert-base-uncased\\snapshots\\15b570cbf88259610b082a167dacc190124f60f6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a100c5f5f904a09a45fb2e6c24550f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedf0488ed14441faf18655efbe33eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5631b17f1a4b6b9affd84aaf8dc99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. Tokenization\n",
    "# -----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = Dataset.from_pandas(train_df).map(tokenize, batched=True)\n",
    "val_dataset = Dataset.from_pandas(val_df).map(tokenize, batched=True)\n",
    "test_dataset = Dataset.from_pandas(test_df).map(tokenize, batched=True)\n",
    "\n",
    "# Set format (ensure \"labels\" column)\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 6. Focal Loss Implementation\n",
    "# -----------------------------\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        bce_loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, labels, reduction=\"none\"\n",
    "        )\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7. Custom Trainer\n",
    "# -----------------------------\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Apply focal loss\n",
    "        loss_fct = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "        loss = loss_fct(logits, labels.float())\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 8. Model Setup\n",
    "# -----------------------------\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels,\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        label2id={label: str(i) for i, label in enumerate(mlb.classes_)},\n",
    "        id2label={str(i): label for i, label in enumerate(mlb.classes_)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\training_args.py:1573: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 9. Training\n",
    "# -----------------------------\n",
    "def compute_metrics(p):\n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).cpu().numpy() > 0.5\n",
    "    labels = p.label_ids\n",
    "    \n",
    "    return {\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "        \"hamming_loss\": hamming_loss(labels, preds)\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../../model/Bert4.0\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    log_level=\"info\",       # Show detailed logs\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: license_name, family, text. If license_name, family, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 972\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 610\n",
      "  Number of trainable parameters = 124,667,933\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c996a4f8e14c4b8e82ad06308f593a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0405, 'grad_norm': 0.11439289897680283, 'learning_rate': 1.9672131147540985e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0271, 'grad_norm': 0.0758814811706543, 'learning_rate': 1.934426229508197e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0236, 'grad_norm': 0.07778170704841614, 'learning_rate': 1.9016393442622952e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0204, 'grad_norm': 0.06722109019756317, 'learning_rate': 1.8688524590163936e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0188, 'grad_norm': 0.0932110995054245, 'learning_rate': 1.836065573770492e-05, 'epoch': 0.82}\n",
      "{'loss': 0.018, 'grad_norm': 0.07130974531173706, 'learning_rate': 1.8032786885245903e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf13288340f413b9a7b9af24beda3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-61\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-61\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01727002114057541, 'eval_f1_macro': 0.367498240549108, 'eval_f1_micro': 0.7978436657681941, 'eval_hamming_loss': 0.09759271307742355, 'eval_runtime': 53.9866, 'eval_samples_per_second': 0.982, 'eval_steps_per_second': 0.074, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-387] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0169, 'grad_norm': 0.07764017581939697, 'learning_rate': 1.7704918032786887e-05, 'epoch': 1.15}\n",
      "{'loss': 0.0163, 'grad_norm': 0.12719246745109558, 'learning_rate': 1.737704918032787e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0168, 'grad_norm': 0.11566201597452164, 'learning_rate': 1.7049180327868854e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0144, 'grad_norm': 0.06543538719415665, 'learning_rate': 1.6721311475409837e-05, 'epoch': 1.64}\n",
      "{'loss': 0.014, 'grad_norm': 0.10747621953487396, 'learning_rate': 1.639344262295082e-05, 'epoch': 1.8}\n",
      "{'loss': 0.0128, 'grad_norm': 0.1329927146434784, 'learning_rate': 1.6065573770491805e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cefdc45fb2f4edc894054c4fc491317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-122\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-122\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01521281898021698, 'eval_f1_macro': 0.44981964708721967, 'eval_f1_micro': 0.8199737187910644, 'eval_hamming_loss': 0.08913467794404685, 'eval_runtime': 53.0748, 'eval_samples_per_second': 0.999, 'eval_steps_per_second': 0.075, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-61] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0134, 'grad_norm': 0.11253954470157623, 'learning_rate': 1.5737704918032788e-05, 'epoch': 2.13}\n",
      "{'loss': 0.0129, 'grad_norm': 0.2705577313899994, 'learning_rate': 1.5409836065573772e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0116, 'grad_norm': 0.13734114170074463, 'learning_rate': 1.5081967213114754e-05, 'epoch': 2.46}\n",
      "{'loss': 0.0112, 'grad_norm': 0.08426066488027573, 'learning_rate': 1.4754098360655739e-05, 'epoch': 2.62}\n",
      "{'loss': 0.0113, 'grad_norm': 0.10119855403900146, 'learning_rate': 1.4426229508196722e-05, 'epoch': 2.79}\n",
      "{'loss': 0.01, 'grad_norm': 0.12322243303060532, 'learning_rate': 1.4098360655737706e-05, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14af16b91f1a4699bb55ca40a72a3d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-183\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-183\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01475460547953844, 'eval_f1_macro': 0.5279964197296426, 'eval_f1_micro': 0.8382165605095542, 'eval_hamming_loss': 0.0826284970722186, 'eval_runtime': 50.3421, 'eval_samples_per_second': 1.053, 'eval_steps_per_second': 0.079, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-122] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0107, 'grad_norm': 0.06795009225606918, 'learning_rate': 1.377049180327869e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0091, 'grad_norm': 0.077070452272892, 'learning_rate': 1.3442622950819673e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0087, 'grad_norm': 0.09553803503513336, 'learning_rate': 1.3114754098360655e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0088, 'grad_norm': 0.08226407319307327, 'learning_rate': 1.2786885245901642e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0091, 'grad_norm': 0.10462537407875061, 'learning_rate': 1.2459016393442624e-05, 'epoch': 3.77}\n",
      "{'loss': 0.0077, 'grad_norm': 0.10200094431638718, 'learning_rate': 1.2131147540983608e-05, 'epoch': 3.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d220342aae4a7d94ffcf837ca17fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-244\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-244\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014614422805607319, 'eval_f1_macro': 0.5685425134584888, 'eval_f1_micro': 0.8553137003841229, 'eval_hamming_loss': 0.07351984385165908, 'eval_runtime': 51.7762, 'eval_samples_per_second': 1.024, 'eval_steps_per_second': 0.077, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-183] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0073, 'grad_norm': 0.07025521993637085, 'learning_rate': 1.1803278688524591e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0074, 'grad_norm': 0.07960332930088043, 'learning_rate': 1.1475409836065575e-05, 'epoch': 4.26}\n",
      "{'loss': 0.007, 'grad_norm': 0.05971836671233177, 'learning_rate': 1.1147540983606557e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0071, 'grad_norm': 0.07849713414907455, 'learning_rate': 1.0819672131147544e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0068, 'grad_norm': 0.12895247340202332, 'learning_rate': 1.0491803278688525e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0065, 'grad_norm': 0.08169500529766083, 'learning_rate': 1.0163934426229509e-05, 'epoch': 4.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a1a13fe83c460f9528ba70be90e67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-305\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-305\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013690901920199394, 'eval_f1_macro': 0.5615409085426857, 'eval_f1_micro': 0.8538461538461538, 'eval_hamming_loss': 0.0741704619388419, 'eval_runtime': 53.2578, 'eval_samples_per_second': 0.995, 'eval_steps_per_second': 0.075, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-305] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0062, 'grad_norm': 0.06895734369754791, 'learning_rate': 9.836065573770493e-06, 'epoch': 5.08}\n",
      "{'loss': 0.0065, 'grad_norm': 0.06376904994249344, 'learning_rate': 9.508196721311476e-06, 'epoch': 5.25}\n",
      "{'loss': 0.0062, 'grad_norm': 0.06455773115158081, 'learning_rate': 9.18032786885246e-06, 'epoch': 5.41}\n",
      "{'loss': 0.0054, 'grad_norm': 0.05414144694805145, 'learning_rate': 8.852459016393443e-06, 'epoch': 5.57}\n",
      "{'loss': 0.0054, 'grad_norm': 0.04053435102105141, 'learning_rate': 8.524590163934427e-06, 'epoch': 5.74}\n",
      "{'loss': 0.0057, 'grad_norm': 0.08845486491918564, 'learning_rate': 8.19672131147541e-06, 'epoch': 5.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60532614db34412ca0a3e9539d3370ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-366\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-366\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014660362154245377, 'eval_f1_macro': 0.5879635830552704, 'eval_f1_micro': 0.8633461047254151, 'eval_hamming_loss': 0.06961613532856213, 'eval_runtime': 54.0349, 'eval_samples_per_second': 0.981, 'eval_steps_per_second': 0.074, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-244] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.006, 'grad_norm': 0.07076963782310486, 'learning_rate': 7.868852459016394e-06, 'epoch': 6.07}\n",
      "{'loss': 0.005, 'grad_norm': 0.05282030627131462, 'learning_rate': 7.540983606557377e-06, 'epoch': 6.23}\n",
      "{'loss': 0.0054, 'grad_norm': 0.0750291720032692, 'learning_rate': 7.213114754098361e-06, 'epoch': 6.39}\n",
      "{'loss': 0.0049, 'grad_norm': 0.08564931899309158, 'learning_rate': 6.885245901639345e-06, 'epoch': 6.56}\n",
      "{'loss': 0.005, 'grad_norm': 0.05929868295788765, 'learning_rate': 6.5573770491803276e-06, 'epoch': 6.72}\n",
      "{'loss': 0.0047, 'grad_norm': 0.06613773852586746, 'learning_rate': 6.229508196721312e-06, 'epoch': 6.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892d501cbd9d48b5aadcf07db9abab12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-427\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-427\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014256794936954975, 'eval_f1_macro': 0.591090456295439, 'eval_f1_micro': 0.8663239074550129, 'eval_hamming_loss': 0.06766428106701367, 'eval_runtime': 53.6835, 'eval_samples_per_second': 0.987, 'eval_steps_per_second': 0.075, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-366] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0049, 'grad_norm': 0.051996152848005295, 'learning_rate': 5.9016393442622956e-06, 'epoch': 7.05}\n",
      "{'loss': 0.0048, 'grad_norm': 0.04995713010430336, 'learning_rate': 5.573770491803278e-06, 'epoch': 7.21}\n",
      "{'loss': 0.0045, 'grad_norm': 0.05542890354990959, 'learning_rate': 5.245901639344263e-06, 'epoch': 7.38}\n",
      "{'loss': 0.0046, 'grad_norm': 0.07824521511793137, 'learning_rate': 4.918032786885246e-06, 'epoch': 7.54}\n",
      "{'loss': 0.0046, 'grad_norm': 0.04286443069577217, 'learning_rate': 4.59016393442623e-06, 'epoch': 7.7}\n",
      "{'loss': 0.0047, 'grad_norm': 0.07349569350481033, 'learning_rate': 4.2622950819672135e-06, 'epoch': 7.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbb6fc1ad3d431ea919ffe60105fb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-488\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-488\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014187810942530632, 'eval_f1_macro': 0.5872885320277947, 'eval_f1_micro': 0.8630490956072352, 'eval_hamming_loss': 0.06896551724137931, 'eval_runtime': 53.3295, 'eval_samples_per_second': 0.994, 'eval_steps_per_second': 0.075, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-430] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0045, 'grad_norm': 0.03882031515240669, 'learning_rate': 3.934426229508197e-06, 'epoch': 8.03}\n",
      "{'loss': 0.0045, 'grad_norm': 0.05249963700771332, 'learning_rate': 3.6065573770491806e-06, 'epoch': 8.2}\n",
      "{'loss': 0.0043, 'grad_norm': 0.04327310621738434, 'learning_rate': 3.2786885245901638e-06, 'epoch': 8.36}\n",
      "{'loss': 0.0043, 'grad_norm': 0.049907613545656204, 'learning_rate': 2.9508196721311478e-06, 'epoch': 8.52}\n",
      "{'loss': 0.0041, 'grad_norm': 0.041949931532144547, 'learning_rate': 2.6229508196721314e-06, 'epoch': 8.69}\n",
      "{'loss': 0.0045, 'grad_norm': 0.11130422353744507, 'learning_rate': 2.295081967213115e-06, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24f3181f4c0472b9423e11100edf444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-549\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-549\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014318455941975117, 'eval_f1_macro': 0.6004805539312504, 'eval_f1_micro': 0.8670076726342711, 'eval_hamming_loss': 0.06766428106701367, 'eval_runtime': 53.4912, 'eval_samples_per_second': 0.991, 'eval_steps_per_second': 0.075, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-427] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0044, 'grad_norm': 0.060591962188482285, 'learning_rate': 1.9672131147540985e-06, 'epoch': 9.02}\n",
      "{'loss': 0.0044, 'grad_norm': 0.044623780995607376, 'learning_rate': 1.6393442622950819e-06, 'epoch': 9.18}\n",
      "{'loss': 0.0038, 'grad_norm': 0.043660108000040054, 'learning_rate': 1.3114754098360657e-06, 'epoch': 9.34}\n",
      "{'loss': 0.0041, 'grad_norm': 0.06246509402990341, 'learning_rate': 9.836065573770493e-07, 'epoch': 9.51}\n",
      "{'loss': 0.0043, 'grad_norm': 0.06374526023864746, 'learning_rate': 6.557377049180328e-07, 'epoch': 9.67}\n",
      "{'loss': 0.0042, 'grad_norm': 0.037270937114953995, 'learning_rate': 3.278688524590164e-07, 'epoch': 9.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-610\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-610\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0041, 'grad_norm': 0.03981207311153412, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [..\\..\\model\\Bert4.0\\checkpoint-488] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3573a85a8a2a4cac9743704013fa6215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Bert4.0\\checkpoint-610\n",
      "Configuration saved in ../../model/Bert4.0\\checkpoint-610\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014367332682013512, 'eval_f1_macro': 0.5897142482466144, 'eval_f1_micro': 0.8600770218228498, 'eval_hamming_loss': 0.07091737150292778, 'eval_runtime': 52.4383, 'eval_samples_per_second': 1.011, 'eval_steps_per_second': 0.076, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../model/Bert4.0\\checkpoint-549 (score: 0.6004805539312504).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 29038.2895, 'train_samples_per_second': 0.335, 'train_steps_per_second': 0.021, 'train_loss': 0.00911996128251318, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=610, training_loss=0.00911996128251318, metrics={'train_runtime': 29038.2895, 'train_samples_per_second': 0.335, 'train_steps_per_second': 0.021, 'total_flos': 2558059437957120.0, 'train_loss': 0.00911996128251318, 'epoch': 10.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 10. Train the Model\n",
    "# -----------------------------\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/Roberta\n",
      "Configuration saved in ../../model/Roberta\\config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../../model/Roberta\\\\tokenizer_config.json',\n",
       " '../../model/Roberta\\\\special_tokens_map.json',\n",
       " '../../model/Roberta\\\\vocab.json',\n",
       " '../../model/Roberta\\\\merges.txt',\n",
       " '../../model/Roberta\\\\added_tokens.json',\n",
       " '../../model/Roberta\\\\tokenizer.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"../../model/Roberta\")  # Saves model and tokenizer\n",
    "tokenizer.save_pretrained(\"../../model/Roberta\")  # Save tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67897c10045242928701df91f633af4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 54\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5353fedf46d46fcae3f2377f2f34928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Test Metrics ---\n",
      "F1 Macro: 0.6237\n",
      "F1 Micro: 0.6896\n",
      "Hamming Loss: 0.2075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 11. Threshold Optimization\n",
    "# -----------------------------\n",
    "def optimize_thresholds(y_true, y_pred_proba):\n",
    "    thresholds = {}\n",
    "    for i in range(y_true.shape[1]):\n",
    "        precision, recall, th = precision_recall_curve(y_true[:, i], y_pred_proba[:, i])\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "        optimal_th = th[np.argmax(f1_scores)]\n",
    "        thresholds[i] = optimal_th\n",
    "    return thresholds\n",
    "\n",
    "# Get validation predictions\n",
    "val_preds = trainer.predict(val_dataset)\n",
    "val_pred_proba = torch.sigmoid(torch.tensor(val_preds.predictions)).numpy()\n",
    "val_labels = val_preds.label_ids\n",
    "\n",
    "# Find optimal thresholds\n",
    "optimal_thresholds = optimize_thresholds(val_labels, val_pred_proba)\n",
    "\n",
    "# -----------------------------\n",
    "# 12. Final Evaluation\n",
    "# -----------------------------\n",
    "test_preds = trainer.predict(test_dataset)\n",
    "test_pred_proba = torch.sigmoid(torch.tensor(test_preds.predictions)).numpy()\n",
    "test_labels = test_preds.label_ids\n",
    "\n",
    "# Apply optimized thresholds\n",
    "final_test_preds = (test_pred_proba > np.array(list(optimal_thresholds.values()))).astype(int)\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\n--- Final Test Metrics ---\")\n",
    "print(f\"F1 Macro: {f1_score(test_labels, final_test_preds, average='macro'):.4f}\")\n",
    "print(f\"F1 Micro: {f1_score(test_labels, final_test_preds, average='micro'):.4f}\")\n",
    "print(f\"Hamming Loss: {hamming_loss(test_labels, final_test_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../model/LegalBert\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../../model/LegalBert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Anti-DRM (obligation/WARNING)\",\n",
      "    \"1\": \"Anti-Tivoization (obligation/WARNING)\",\n",
      "    \"2\": \"Copyleft (network protective) (obligation/ALARM)\",\n",
      "    \"3\": \"Copyleft (strong) (obligation/WARNING)\",\n",
      "    \"4\": \"Copyleft (weak) (obligation/WARNING)\",\n",
      "    \"5\": \"Declare modification in source code (obligation/WARNING)\",\n",
      "    \"6\": \"Deprecated License (other/INFORMATION)\",\n",
      "    \"7\": \"Display acknowledgement message (obligation/WARNING)\",\n",
      "    \"8\": \"Display additional information (obligation/WARNING)\",\n",
      "    \"9\": \"Display copyright notice (obligation/INFORMATION)\",\n",
      "    \"10\": \"Display license in binary (obligation/INFORMATION)\",\n",
      "    \"11\": \"Display license in the source (obligation/INFORMATION)\",\n",
      "    \"12\": \"Doing Business with US (other/ALARM)\",\n",
      "    \"13\": \"Endorsement prohibited (prohibition/INFORMATION)\",\n",
      "    \"14\": \"Jurisdiction specific (other/WARNING)\",\n",
      "    \"15\": \"Keep copy of source code available (obligation/WARNING)\",\n",
      "    \"16\": \"License upgrade allowed (right/INFORMATION)\",\n",
      "    \"17\": \"Limitation (limitation/WARNING)\",\n",
      "    \"18\": \"No further restrictions permitted (prohibition/INFORMATION)\",\n",
      "    \"19\": \"Patent grant (other/INFORMATION)\",\n",
      "    \"20\": \"Permissive (right/INFORMATION)\",\n",
      "    \"21\": \"Provide source code location (obligation/WARNING)\",\n",
      "    \"22\": \"Public Domain (other/INFORMATION)\",\n",
      "    \"23\": \"Severe patent retaliation (other/ALARM)\",\n",
      "    \"24\": \"Standard patent retaliation (other/WARNING)\",\n",
      "    \"25\": \"Unclear or Ambiguous (other/ALARM)\",\n",
      "    \"26\": \"Usage notice in advertisement (obligation/INFORMATION)\",\n",
      "    \"27\": \"Use in distributed software (right/INFORMATION)\",\n",
      "    \"28\": \"Written offer to request source code (obligation/WARNING)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Anti-DRM (obligation/WARNING)\": \"0\",\n",
      "    \"Anti-Tivoization (obligation/WARNING)\": \"1\",\n",
      "    \"Copyleft (network protective) (obligation/ALARM)\": \"2\",\n",
      "    \"Copyleft (strong) (obligation/WARNING)\": \"3\",\n",
      "    \"Copyleft (weak) (obligation/WARNING)\": \"4\",\n",
      "    \"Declare modification in source code (obligation/WARNING)\": \"5\",\n",
      "    \"Deprecated License (other/INFORMATION)\": \"6\",\n",
      "    \"Display acknowledgement message (obligation/WARNING)\": \"7\",\n",
      "    \"Display additional information (obligation/WARNING)\": \"8\",\n",
      "    \"Display copyright notice (obligation/INFORMATION)\": \"9\",\n",
      "    \"Display license in binary (obligation/INFORMATION)\": \"10\",\n",
      "    \"Display license in the source (obligation/INFORMATION)\": \"11\",\n",
      "    \"Doing Business with US (other/ALARM)\": \"12\",\n",
      "    \"Endorsement prohibited (prohibition/INFORMATION)\": \"13\",\n",
      "    \"Jurisdiction specific (other/WARNING)\": \"14\",\n",
      "    \"Keep copy of source code available (obligation/WARNING)\": \"15\",\n",
      "    \"License upgrade allowed (right/INFORMATION)\": \"16\",\n",
      "    \"Limitation (limitation/WARNING)\": \"17\",\n",
      "    \"No further restrictions permitted (prohibition/INFORMATION)\": \"18\",\n",
      "    \"Patent grant (other/INFORMATION)\": \"19\",\n",
      "    \"Permissive (right/INFORMATION)\": \"20\",\n",
      "    \"Provide source code location (obligation/WARNING)\": \"21\",\n",
      "    \"Public Domain (other/INFORMATION)\": \"22\",\n",
      "    \"Severe patent retaliation (other/ALARM)\": \"23\",\n",
      "    \"Standard patent retaliation (other/WARNING)\": \"24\",\n",
      "    \"Unclear or Ambiguous (other/ALARM)\": \"25\",\n",
      "    \"Usage notice in advertisement (obligation/INFORMATION)\": \"26\",\n",
      "    \"Use in distributed software (right/INFORMATION)\": \"27\",\n",
      "    \"Written offer to request source code (obligation/WARNING)\": \"28\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_directory = \"../../model/LegalBert\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e205b80ec4e24525af931e34b60945ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get validation predictions\n",
    "val_preds = trainer.predict(val_dataset)\n",
    "val_pred_proba = torch.sigmoid(torch.tensor(val_preds.predictions)).numpy()\n",
    "val_labels = val_preds.label_ids\n",
    "\n",
    "# Find optimal thresholds\n",
    "optimal_thresholds = optimize_thresholds(val_labels, val_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 54\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe779222d04b4b079e812476cf2fd6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Test Metrics ---\n",
      "F1 Macro: 0.6397\n",
      "F1 Micro: 0.6956\n",
      "Hamming Loss: 0.2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 12. Final Evaluation\n",
    "# -----------------------------\n",
    "test_preds = trainer.predict(test_dataset)\n",
    "test_pred_proba = torch.sigmoid(torch.tensor(test_preds.predictions)).numpy()\n",
    "test_labels = test_preds.label_ids\n",
    "\n",
    "# Apply optimized thresholds\n",
    "final_test_preds = (test_pred_proba > np.array(list(optimal_thresholds.values()))).astype(int)\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\n--- Final Test Metrics ---\")\n",
    "print(f\"F1 Macro: {f1_score(test_labels, final_test_preds, average='macro'):.4f}\")\n",
    "print(f\"F1 Micro: {f1_score(test_labels, final_test_preds, average='micro'):.4f}\")\n",
    "print(f\"Hamming Loss: {hamming_loss(test_labels, final_test_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "loading configuration file config.json from cache at C:\\Users\\NPARSHO\\.cache\\huggingface\\hub\\models--nlpaueb--legal-bert-base-uncased\\snapshots\\15b570cbf88259610b082a167dacc190124f60f6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Anti-DRM (obligation/WARNING)\",\n",
      "    \"1\": \"Anti-Tivoization (obligation/WARNING)\",\n",
      "    \"10\": \"Display license in binary (obligation/INFORMATION)\",\n",
      "    \"11\": \"Display license in the source (obligation/INFORMATION)\",\n",
      "    \"12\": \"Doing Business with US (other/ALARM)\",\n",
      "    \"13\": \"Endorsement prohibited (prohibition/INFORMATION)\",\n",
      "    \"14\": \"Jurisdiction specific (other/WARNING)\",\n",
      "    \"15\": \"Keep copy of source code available (obligation/WARNING)\",\n",
      "    \"16\": \"License upgrade allowed (right/INFORMATION)\",\n",
      "    \"17\": \"Limitation (limitation/WARNING)\",\n",
      "    \"18\": \"No further restrictions permitted (prohibition/INFORMATION)\",\n",
      "    \"19\": \"Patent grant (other/INFORMATION)\",\n",
      "    \"2\": \"Copyleft (network protective) (obligation/ALARM)\",\n",
      "    \"20\": \"Permissive (right/INFORMATION)\",\n",
      "    \"21\": \"Provide source code location (obligation/WARNING)\",\n",
      "    \"22\": \"Public Domain (other/INFORMATION)\",\n",
      "    \"23\": \"Severe patent retaliation (other/ALARM)\",\n",
      "    \"24\": \"Standard patent retaliation (other/WARNING)\",\n",
      "    \"25\": \"Unclear or Ambiguous (other/ALARM)\",\n",
      "    \"26\": \"Usage notice in advertisement (obligation/INFORMATION)\",\n",
      "    \"27\": \"Use in distributed software (right/INFORMATION)\",\n",
      "    \"28\": \"Written offer to request source code (obligation/WARNING)\",\n",
      "    \"3\": \"Copyleft (strong) (obligation/WARNING)\",\n",
      "    \"4\": \"Copyleft (weak) (obligation/WARNING)\",\n",
      "    \"5\": \"Declare modification in source code (obligation/WARNING)\",\n",
      "    \"6\": \"Deprecated License (other/INFORMATION)\",\n",
      "    \"7\": \"Display acknowledgement message (obligation/WARNING)\",\n",
      "    \"8\": \"Display additional information (obligation/WARNING)\",\n",
      "    \"9\": \"Display copyright notice (obligation/INFORMATION)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Anti-DRM (obligation/WARNING)\": \"0\",\n",
      "    \"Anti-Tivoization (obligation/WARNING)\": \"1\",\n",
      "    \"Copyleft (network protective) (obligation/ALARM)\": \"2\",\n",
      "    \"Copyleft (strong) (obligation/WARNING)\": \"3\",\n",
      "    \"Copyleft (weak) (obligation/WARNING)\": \"4\",\n",
      "    \"Declare modification in source code (obligation/WARNING)\": \"5\",\n",
      "    \"Deprecated License (other/INFORMATION)\": \"6\",\n",
      "    \"Display acknowledgement message (obligation/WARNING)\": \"7\",\n",
      "    \"Display additional information (obligation/WARNING)\": \"8\",\n",
      "    \"Display copyright notice (obligation/INFORMATION)\": \"9\",\n",
      "    \"Display license in binary (obligation/INFORMATION)\": \"10\",\n",
      "    \"Display license in the source (obligation/INFORMATION)\": \"11\",\n",
      "    \"Doing Business with US (other/ALARM)\": \"12\",\n",
      "    \"Endorsement prohibited (prohibition/INFORMATION)\": \"13\",\n",
      "    \"Jurisdiction specific (other/WARNING)\": \"14\",\n",
      "    \"Keep copy of source code available (obligation/WARNING)\": \"15\",\n",
      "    \"License upgrade allowed (right/INFORMATION)\": \"16\",\n",
      "    \"Limitation (limitation/WARNING)\": \"17\",\n",
      "    \"No further restrictions permitted (prohibition/INFORMATION)\": \"18\",\n",
      "    \"Patent grant (other/INFORMATION)\": \"19\",\n",
      "    \"Permissive (right/INFORMATION)\": \"20\",\n",
      "    \"Provide source code location (obligation/WARNING)\": \"21\",\n",
      "    \"Public Domain (other/INFORMATION)\": \"22\",\n",
      "    \"Severe patent retaliation (other/ALARM)\": \"23\",\n",
      "    \"Standard patent retaliation (other/WARNING)\": \"24\",\n",
      "    \"Unclear or Ambiguous (other/ALARM)\": \"25\",\n",
      "    \"Usage notice in advertisement (obligation/INFORMATION)\": \"26\",\n",
      "    \"Use in distributed software (right/INFORMATION)\": \"27\",\n",
      "    \"Written offer to request source code (obligation/WARNING)\": \"28\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-03-13 00:17:26,524] A new study created in memory with name: no-name-efbdedce-3c48-4a0d-a243-d7919653a2e9\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trial: {'learning_rate': 3.737231992488263e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 12, 'weight_decay': 0.030357542715208397, 'alpha': 0.4233822628381545, 'gamma': 2.077604194362665}\n",
      "loading configuration file config.json from cache at C:\\Users\\NPARSHO\\.cache\\huggingface\\hub\\models--nlpaueb--legal-bert-base-uncased\\snapshots\\15b570cbf88259610b082a167dacc190124f60f6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Anti-DRM (obligation/WARNING)\",\n",
      "    \"1\": \"Anti-Tivoization (obligation/WARNING)\",\n",
      "    \"10\": \"Display license in binary (obligation/INFORMATION)\",\n",
      "    \"11\": \"Display license in the source (obligation/INFORMATION)\",\n",
      "    \"12\": \"Doing Business with US (other/ALARM)\",\n",
      "    \"13\": \"Endorsement prohibited (prohibition/INFORMATION)\",\n",
      "    \"14\": \"Jurisdiction specific (other/WARNING)\",\n",
      "    \"15\": \"Keep copy of source code available (obligation/WARNING)\",\n",
      "    \"16\": \"License upgrade allowed (right/INFORMATION)\",\n",
      "    \"17\": \"Limitation (limitation/WARNING)\",\n",
      "    \"18\": \"No further restrictions permitted (prohibition/INFORMATION)\",\n",
      "    \"19\": \"Patent grant (other/INFORMATION)\",\n",
      "    \"2\": \"Copyleft (network protective) (obligation/ALARM)\",\n",
      "    \"20\": \"Permissive (right/INFORMATION)\",\n",
      "    \"21\": \"Provide source code location (obligation/WARNING)\",\n",
      "    \"22\": \"Public Domain (other/INFORMATION)\",\n",
      "    \"23\": \"Severe patent retaliation (other/ALARM)\",\n",
      "    \"24\": \"Standard patent retaliation (other/WARNING)\",\n",
      "    \"25\": \"Unclear or Ambiguous (other/ALARM)\",\n",
      "    \"26\": \"Usage notice in advertisement (obligation/INFORMATION)\",\n",
      "    \"27\": \"Use in distributed software (right/INFORMATION)\",\n",
      "    \"28\": \"Written offer to request source code (obligation/WARNING)\",\n",
      "    \"3\": \"Copyleft (strong) (obligation/WARNING)\",\n",
      "    \"4\": \"Copyleft (weak) (obligation/WARNING)\",\n",
      "    \"5\": \"Declare modification in source code (obligation/WARNING)\",\n",
      "    \"6\": \"Deprecated License (other/INFORMATION)\",\n",
      "    \"7\": \"Display acknowledgement message (obligation/WARNING)\",\n",
      "    \"8\": \"Display additional information (obligation/WARNING)\",\n",
      "    \"9\": \"Display copyright notice (obligation/INFORMATION)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Anti-DRM (obligation/WARNING)\": \"0\",\n",
      "    \"Anti-Tivoization (obligation/WARNING)\": \"1\",\n",
      "    \"Copyleft (network protective) (obligation/ALARM)\": \"2\",\n",
      "    \"Copyleft (strong) (obligation/WARNING)\": \"3\",\n",
      "    \"Copyleft (weak) (obligation/WARNING)\": \"4\",\n",
      "    \"Declare modification in source code (obligation/WARNING)\": \"5\",\n",
      "    \"Deprecated License (other/INFORMATION)\": \"6\",\n",
      "    \"Display acknowledgement message (obligation/WARNING)\": \"7\",\n",
      "    \"Display additional information (obligation/WARNING)\": \"8\",\n",
      "    \"Display copyright notice (obligation/INFORMATION)\": \"9\",\n",
      "    \"Display license in binary (obligation/INFORMATION)\": \"10\",\n",
      "    \"Display license in the source (obligation/INFORMATION)\": \"11\",\n",
      "    \"Doing Business with US (other/ALARM)\": \"12\",\n",
      "    \"Endorsement prohibited (prohibition/INFORMATION)\": \"13\",\n",
      "    \"Jurisdiction specific (other/WARNING)\": \"14\",\n",
      "    \"Keep copy of source code available (obligation/WARNING)\": \"15\",\n",
      "    \"License upgrade allowed (right/INFORMATION)\": \"16\",\n",
      "    \"Limitation (limitation/WARNING)\": \"17\",\n",
      "    \"No further restrictions permitted (prohibition/INFORMATION)\": \"18\",\n",
      "    \"Patent grant (other/INFORMATION)\": \"19\",\n",
      "    \"Permissive (right/INFORMATION)\": \"20\",\n",
      "    \"Provide source code location (obligation/WARNING)\": \"21\",\n",
      "    \"Public Domain (other/INFORMATION)\": \"22\",\n",
      "    \"Severe patent retaliation (other/ALARM)\": \"23\",\n",
      "    \"Standard patent retaliation (other/WARNING)\": \"24\",\n",
      "    \"Unclear or Ambiguous (other/ALARM)\": \"25\",\n",
      "    \"Usage notice in advertisement (obligation/INFORMATION)\": \"26\",\n",
      "    \"Use in distributed software (right/INFORMATION)\": \"27\",\n",
      "    \"Written offer to request source code (obligation/WARNING)\": \"28\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: license_name, family, text. If license_name, family, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 972\n",
      "  Num Epochs = 12\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 732\n",
      "  Number of trainable parameters = 109,504,541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5da6be9afd248cdbccbad4591a40809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d96b25634d94724ad6fad690d6517c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-61\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-61\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017661551013588905, 'eval_f1_macro': 0.32713001329340347, 'eval_f1_micro': 0.7896879240162822, 'eval_hamming_loss': 0.10084580351333768, 'eval_runtime': 65.7015, 'eval_samples_per_second': 0.807, 'eval_steps_per_second': 0.061, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89c0664cde4481cbe92c1bc01b539eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-122\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-122\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015107940882444382, 'eval_f1_macro': 0.45192000123258314, 'eval_f1_micro': 0.8258575197889182, 'eval_hamming_loss': 0.08588158750813273, 'eval_runtime': 65.5585, 'eval_samples_per_second': 0.808, 'eval_steps_per_second': 0.061, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b42524bb394f1f8f2e88d5c20d16fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-183\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-183\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01468051690608263, 'eval_f1_macro': 0.5134380507339251, 'eval_f1_micro': 0.8435897435897436, 'eval_hamming_loss': 0.07937540663630449, 'eval_runtime': 65.9055, 'eval_samples_per_second': 0.804, 'eval_steps_per_second': 0.061, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3958ffd29d854e1490027ff5a6e622a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-244\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-244\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014503732323646545, 'eval_f1_macro': 0.5882168617029118, 'eval_f1_micro': 0.8582375478927203, 'eval_hamming_loss': 0.07221860767729343, 'eval_runtime': 65.9639, 'eval_samples_per_second': 0.803, 'eval_steps_per_second': 0.061, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7794b8f82508458681a1b30f6958b54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-305\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-305\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014879824593663216, 'eval_f1_macro': 0.5797974374466691, 'eval_f1_micro': 0.8556701030927835, 'eval_hamming_loss': 0.07286922576447626, 'eval_runtime': 65.9471, 'eval_samples_per_second': 0.804, 'eval_steps_per_second': 0.061, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1b20bd0c3b42e492fa0a35cf8b8e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-366\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-366\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015594271942973137, 'eval_f1_macro': 0.6083628785549509, 'eval_f1_micro': 0.8560509554140128, 'eval_hamming_loss': 0.07351984385165908, 'eval_runtime': 66.3287, 'eval_samples_per_second': 0.799, 'eval_steps_per_second': 0.06, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c46b7ea22649c9930e32bc150bee90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-427\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-427\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014932326972484589, 'eval_f1_macro': 0.6141900765603633, 'eval_f1_micro': 0.8663239074550129, 'eval_hamming_loss': 0.06766428106701367, 'eval_runtime': 66.0796, 'eval_samples_per_second': 0.802, 'eval_steps_per_second': 0.061, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f90709eb04445c992af44a7bda1e158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-488\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-488\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015610205940902233, 'eval_f1_macro': 0.6115016235944682, 'eval_f1_micro': 0.8611825192802056, 'eval_hamming_loss': 0.07026675341574495, 'eval_runtime': 65.9635, 'eval_samples_per_second': 0.803, 'eval_steps_per_second': 0.061, 'epoch': 8.0}\n",
      "{'loss': 0.009, 'grad_norm': 0.02335641346871853, 'learning_rate': 1.1844778992585751e-05, 'epoch': 8.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f7410e87df4432aecb5e57649ea6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-549\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-549\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0153913339599967, 'eval_f1_macro': 0.6047692285556783, 'eval_f1_micro': 0.8600770218228498, 'eval_hamming_loss': 0.07091737150292778, 'eval_runtime': 66.1347, 'eval_samples_per_second': 0.801, 'eval_steps_per_second': 0.06, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03fdf101daa4ba8a040b6bb1b81a760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-610\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-610\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015886398032307625, 'eval_f1_macro': 0.6060601940675816, 'eval_f1_micro': 0.8578745198463509, 'eval_hamming_loss': 0.07221860767729343, 'eval_runtime': 65.725, 'eval_samples_per_second': 0.806, 'eval_steps_per_second': 0.061, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949c431c3a5e45f980b50b30b7d2b84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-671\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-671\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016224214807152748, 'eval_f1_macro': 0.6076854291125322, 'eval_f1_micro': 0.8604353393085787, 'eval_hamming_loss': 0.07091737150292778, 'eval_runtime': 65.9028, 'eval_samples_per_second': 0.804, 'eval_steps_per_second': 0.061, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-732\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-732\\config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc662e42e4d45aeb4086090271542eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-0\\checkpoint-732\n",
      "Configuration saved in ../../model/hp_search\\run-0\\checkpoint-732\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016121268272399902, 'eval_f1_macro': 0.6076854291125322, 'eval_f1_micro': 0.8604353393085787, 'eval_hamming_loss': 0.07091737150292778, 'eval_runtime': 66.48, 'eval_samples_per_second': 0.797, 'eval_steps_per_second': 0.06, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[I 2025-03-13 10:12:00,352] Trial 0 finished with value: 1.5390381399240387 and parameters: {'learning_rate': 3.737231992488263e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 12, 'weight_decay': 0.030357542715208397, 'alpha': 0.4233822628381545, 'gamma': 2.077604194362665}. Best is trial 0 with value: 1.5390381399240387.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trial: {'learning_rate': 4.150579859926717e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 14, 'weight_decay': 0.014580526204328113, 'alpha': 0.4989228897662774, 'gamma': 2.0623051788188915}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 35672.2796, 'train_samples_per_second': 0.327, 'train_steps_per_second': 0.021, 'train_loss': 0.006994806107927541, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\NPARSHO\\.cache\\huggingface\\hub\\models--nlpaueb--legal-bert-base-uncased\\snapshots\\15b570cbf88259610b082a167dacc190124f60f6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Anti-DRM (obligation/WARNING)\",\n",
      "    \"1\": \"Anti-Tivoization (obligation/WARNING)\",\n",
      "    \"10\": \"Display license in binary (obligation/INFORMATION)\",\n",
      "    \"11\": \"Display license in the source (obligation/INFORMATION)\",\n",
      "    \"12\": \"Doing Business with US (other/ALARM)\",\n",
      "    \"13\": \"Endorsement prohibited (prohibition/INFORMATION)\",\n",
      "    \"14\": \"Jurisdiction specific (other/WARNING)\",\n",
      "    \"15\": \"Keep copy of source code available (obligation/WARNING)\",\n",
      "    \"16\": \"License upgrade allowed (right/INFORMATION)\",\n",
      "    \"17\": \"Limitation (limitation/WARNING)\",\n",
      "    \"18\": \"No further restrictions permitted (prohibition/INFORMATION)\",\n",
      "    \"19\": \"Patent grant (other/INFORMATION)\",\n",
      "    \"2\": \"Copyleft (network protective) (obligation/ALARM)\",\n",
      "    \"20\": \"Permissive (right/INFORMATION)\",\n",
      "    \"21\": \"Provide source code location (obligation/WARNING)\",\n",
      "    \"22\": \"Public Domain (other/INFORMATION)\",\n",
      "    \"23\": \"Severe patent retaliation (other/ALARM)\",\n",
      "    \"24\": \"Standard patent retaliation (other/WARNING)\",\n",
      "    \"25\": \"Unclear or Ambiguous (other/ALARM)\",\n",
      "    \"26\": \"Usage notice in advertisement (obligation/INFORMATION)\",\n",
      "    \"27\": \"Use in distributed software (right/INFORMATION)\",\n",
      "    \"28\": \"Written offer to request source code (obligation/WARNING)\",\n",
      "    \"3\": \"Copyleft (strong) (obligation/WARNING)\",\n",
      "    \"4\": \"Copyleft (weak) (obligation/WARNING)\",\n",
      "    \"5\": \"Declare modification in source code (obligation/WARNING)\",\n",
      "    \"6\": \"Deprecated License (other/INFORMATION)\",\n",
      "    \"7\": \"Display acknowledgement message (obligation/WARNING)\",\n",
      "    \"8\": \"Display additional information (obligation/WARNING)\",\n",
      "    \"9\": \"Display copyright notice (obligation/INFORMATION)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Anti-DRM (obligation/WARNING)\": \"0\",\n",
      "    \"Anti-Tivoization (obligation/WARNING)\": \"1\",\n",
      "    \"Copyleft (network protective) (obligation/ALARM)\": \"2\",\n",
      "    \"Copyleft (strong) (obligation/WARNING)\": \"3\",\n",
      "    \"Copyleft (weak) (obligation/WARNING)\": \"4\",\n",
      "    \"Declare modification in source code (obligation/WARNING)\": \"5\",\n",
      "    \"Deprecated License (other/INFORMATION)\": \"6\",\n",
      "    \"Display acknowledgement message (obligation/WARNING)\": \"7\",\n",
      "    \"Display additional information (obligation/WARNING)\": \"8\",\n",
      "    \"Display copyright notice (obligation/INFORMATION)\": \"9\",\n",
      "    \"Display license in binary (obligation/INFORMATION)\": \"10\",\n",
      "    \"Display license in the source (obligation/INFORMATION)\": \"11\",\n",
      "    \"Doing Business with US (other/ALARM)\": \"12\",\n",
      "    \"Endorsement prohibited (prohibition/INFORMATION)\": \"13\",\n",
      "    \"Jurisdiction specific (other/WARNING)\": \"14\",\n",
      "    \"Keep copy of source code available (obligation/WARNING)\": \"15\",\n",
      "    \"License upgrade allowed (right/INFORMATION)\": \"16\",\n",
      "    \"Limitation (limitation/WARNING)\": \"17\",\n",
      "    \"No further restrictions permitted (prohibition/INFORMATION)\": \"18\",\n",
      "    \"Patent grant (other/INFORMATION)\": \"19\",\n",
      "    \"Permissive (right/INFORMATION)\": \"20\",\n",
      "    \"Provide source code location (obligation/WARNING)\": \"21\",\n",
      "    \"Public Domain (other/INFORMATION)\": \"22\",\n",
      "    \"Severe patent retaliation (other/ALARM)\": \"23\",\n",
      "    \"Standard patent retaliation (other/WARNING)\": \"24\",\n",
      "    \"Unclear or Ambiguous (other/ALARM)\": \"25\",\n",
      "    \"Usage notice in advertisement (obligation/INFORMATION)\": \"26\",\n",
      "    \"Use in distributed software (right/INFORMATION)\": \"27\",\n",
      "    \"Written offer to request source code (obligation/WARNING)\": \"28\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: license_name, family, text. If license_name, family, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 972\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,708\n",
      "  Number of trainable parameters = 109,504,541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fc210f88f3459a8346a7aa7b468b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2441eb38494c7caa6a04f01503ad12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-122\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-122\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01722702756524086, 'eval_f1_macro': 0.3269749707154933, 'eval_f1_micro': 0.7757909215955984, 'eval_hamming_loss': 0.10605074821080027, 'eval_runtime': 55.7149, 'eval_samples_per_second': 0.951, 'eval_steps_per_second': 0.072, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934e196ec4f84e8fb746dda12a839753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-244\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-244\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01484353095293045, 'eval_f1_macro': 0.557358453453057, 'eval_f1_micro': 0.854614412136536, 'eval_hamming_loss': 0.07482108002602472, 'eval_runtime': 54.237, 'eval_samples_per_second': 0.977, 'eval_steps_per_second': 0.074, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cf9ba122934a86bc03421bd608f350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-366\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-366\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014910904690623283, 'eval_f1_macro': 0.611887076510675, 'eval_f1_micro': 0.8629441624365483, 'eval_hamming_loss': 0.07026675341574495, 'eval_runtime': 54.2167, 'eval_samples_per_second': 0.978, 'eval_steps_per_second': 0.074, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef3a1e7e0364e78b795a520af39f39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-488\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-488\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015760479494929314, 'eval_f1_macro': 0.616392282487043, 'eval_f1_micro': 0.8673469387755102, 'eval_hamming_loss': 0.06766428106701367, 'eval_runtime': 54.2425, 'eval_samples_per_second': 0.977, 'eval_steps_per_second': 0.074, 'epoch': 4.0}\n",
      "{'loss': 0.0103, 'grad_norm': 0.03576251491904259, 'learning_rate': 2.935538917325219e-05, 'epoch': 4.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bc6b4b2c3642768f9db894d5ddfd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-610\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-610\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017529094591736794, 'eval_f1_macro': 0.6167742608997735, 'eval_f1_micro': 0.8575063613231552, 'eval_hamming_loss': 0.07286922576447626, 'eval_runtime': 54.1554, 'eval_samples_per_second': 0.979, 'eval_steps_per_second': 0.074, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176a306190f040459627496b9a989502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-732\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-732\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017601365223526955, 'eval_f1_macro': 0.630371392397419, 'eval_f1_micro': 0.8710089399744572, 'eval_hamming_loss': 0.06571242680546518, 'eval_runtime': 53.7403, 'eval_samples_per_second': 0.986, 'eval_steps_per_second': 0.074, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d553340462a4e979f7de5ec0e6f8f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-854\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-854\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01862945780158043, 'eval_f1_macro': 0.638877947430367, 'eval_f1_micro': 0.8724489795918368, 'eval_hamming_loss': 0.06506180871828236, 'eval_runtime': 55.4152, 'eval_samples_per_second': 0.956, 'eval_steps_per_second': 0.072, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a744c14706b4b1b804bcd41d63ce395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-976\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-976\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018686309456825256, 'eval_f1_macro': 0.6307129613610022, 'eval_f1_micro': 0.8629961587708067, 'eval_hamming_loss': 0.06961613532856213, 'eval_runtime': 54.1944, 'eval_samples_per_second': 0.978, 'eval_steps_per_second': 0.074, 'epoch': 8.0}\n",
      "{'loss': 0.0023, 'grad_norm': 0.033410124480724335, 'learning_rate': 1.720497974723721e-05, 'epoch': 8.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585f93da45534dccb319e1e5a2891035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-1098\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-1098\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.019458139315247536, 'eval_f1_macro': 0.6252391506029013, 'eval_f1_micro': 0.8695652173913043, 'eval_hamming_loss': 0.06636304489264802, 'eval_runtime': 55.0358, 'eval_samples_per_second': 0.963, 'eval_steps_per_second': 0.073, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc28e17f61542b1a654fabc422378cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-1220\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-1220\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01992134191095829, 'eval_f1_macro': 0.6273256929798248, 'eval_f1_micro': 0.8655569782330346, 'eval_hamming_loss': 0.06831489915419649, 'eval_runtime': 54.3962, 'eval_samples_per_second': 0.974, 'eval_steps_per_second': 0.074, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36d407d546f4298ac607a596716c299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-1342\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-1342\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.020407995209097862, 'eval_f1_macro': 0.6230612921636999, 'eval_f1_micro': 0.8666666666666667, 'eval_hamming_loss': 0.06766428106701367, 'eval_runtime': 53.4858, 'eval_samples_per_second': 0.991, 'eval_steps_per_second': 0.075, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d54209b6680491ca1ecf2f6b44884ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-1464\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-1464\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02054348774254322, 'eval_f1_macro': 0.6230612921636999, 'eval_f1_micro': 0.8666666666666667, 'eval_hamming_loss': 0.06766428106701367, 'eval_runtime': 55.2696, 'eval_samples_per_second': 0.959, 'eval_steps_per_second': 0.072, 'epoch': 12.0}\n",
      "{'loss': 0.0014, 'grad_norm': 0.013558023609220982, 'learning_rate': 5.054570321222231e-06, 'epoch': 12.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a502467dd4240cfb220b728f64c2823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-1586\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-1586\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02073541469871998, 'eval_f1_macro': 0.6230612921636999, 'eval_f1_micro': 0.8666666666666667, 'eval_hamming_loss': 0.06766428106701367, 'eval_runtime': 54.5817, 'eval_samples_per_second': 0.971, 'eval_steps_per_second': 0.073, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-1708\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-1708\\config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacdedfc4f9a4916a6f74f518d893c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-1\\checkpoint-1708\n",
      "Configuration saved in ../../model/hp_search\\run-1\\checkpoint-1708\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02086891047656536, 'eval_f1_macro': 0.6230612921636999, 'eval_f1_micro': 0.8666666666666667, 'eval_hamming_loss': 0.06766428106701367, 'eval_runtime': 53.3848, 'eval_samples_per_second': 0.993, 'eval_steps_per_second': 0.075, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[I 2025-03-13 15:54:48,575] Trial 1 finished with value: 1.5573922398973803 and parameters: {'learning_rate': 4.150579859926717e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 14, 'weight_decay': 0.014580526204328113, 'alpha': 0.4989228897662774, 'gamma': 2.0623051788188915}. Best is trial 1 with value: 1.5573922398973803.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trial: {'learning_rate': 2.154275755551988e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 6, 'weight_decay': 0.05291984206452107, 'alpha': 0.42034951319231434, 'gamma': 1.819836017561793}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 20565.5124, 'train_samples_per_second': 0.662, 'train_steps_per_second': 0.083, 'train_loss': 0.004229242684411221, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\NPARSHO\\.cache\\huggingface\\hub\\models--nlpaueb--legal-bert-base-uncased\\snapshots\\15b570cbf88259610b082a167dacc190124f60f6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Anti-DRM (obligation/WARNING)\",\n",
      "    \"1\": \"Anti-Tivoization (obligation/WARNING)\",\n",
      "    \"10\": \"Display license in binary (obligation/INFORMATION)\",\n",
      "    \"11\": \"Display license in the source (obligation/INFORMATION)\",\n",
      "    \"12\": \"Doing Business with US (other/ALARM)\",\n",
      "    \"13\": \"Endorsement prohibited (prohibition/INFORMATION)\",\n",
      "    \"14\": \"Jurisdiction specific (other/WARNING)\",\n",
      "    \"15\": \"Keep copy of source code available (obligation/WARNING)\",\n",
      "    \"16\": \"License upgrade allowed (right/INFORMATION)\",\n",
      "    \"17\": \"Limitation (limitation/WARNING)\",\n",
      "    \"18\": \"No further restrictions permitted (prohibition/INFORMATION)\",\n",
      "    \"19\": \"Patent grant (other/INFORMATION)\",\n",
      "    \"2\": \"Copyleft (network protective) (obligation/ALARM)\",\n",
      "    \"20\": \"Permissive (right/INFORMATION)\",\n",
      "    \"21\": \"Provide source code location (obligation/WARNING)\",\n",
      "    \"22\": \"Public Domain (other/INFORMATION)\",\n",
      "    \"23\": \"Severe patent retaliation (other/ALARM)\",\n",
      "    \"24\": \"Standard patent retaliation (other/WARNING)\",\n",
      "    \"25\": \"Unclear or Ambiguous (other/ALARM)\",\n",
      "    \"26\": \"Usage notice in advertisement (obligation/INFORMATION)\",\n",
      "    \"27\": \"Use in distributed software (right/INFORMATION)\",\n",
      "    \"28\": \"Written offer to request source code (obligation/WARNING)\",\n",
      "    \"3\": \"Copyleft (strong) (obligation/WARNING)\",\n",
      "    \"4\": \"Copyleft (weak) (obligation/WARNING)\",\n",
      "    \"5\": \"Declare modification in source code (obligation/WARNING)\",\n",
      "    \"6\": \"Deprecated License (other/INFORMATION)\",\n",
      "    \"7\": \"Display acknowledgement message (obligation/WARNING)\",\n",
      "    \"8\": \"Display additional information (obligation/WARNING)\",\n",
      "    \"9\": \"Display copyright notice (obligation/INFORMATION)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Anti-DRM (obligation/WARNING)\": \"0\",\n",
      "    \"Anti-Tivoization (obligation/WARNING)\": \"1\",\n",
      "    \"Copyleft (network protective) (obligation/ALARM)\": \"2\",\n",
      "    \"Copyleft (strong) (obligation/WARNING)\": \"3\",\n",
      "    \"Copyleft (weak) (obligation/WARNING)\": \"4\",\n",
      "    \"Declare modification in source code (obligation/WARNING)\": \"5\",\n",
      "    \"Deprecated License (other/INFORMATION)\": \"6\",\n",
      "    \"Display acknowledgement message (obligation/WARNING)\": \"7\",\n",
      "    \"Display additional information (obligation/WARNING)\": \"8\",\n",
      "    \"Display copyright notice (obligation/INFORMATION)\": \"9\",\n",
      "    \"Display license in binary (obligation/INFORMATION)\": \"10\",\n",
      "    \"Display license in the source (obligation/INFORMATION)\": \"11\",\n",
      "    \"Doing Business with US (other/ALARM)\": \"12\",\n",
      "    \"Endorsement prohibited (prohibition/INFORMATION)\": \"13\",\n",
      "    \"Jurisdiction specific (other/WARNING)\": \"14\",\n",
      "    \"Keep copy of source code available (obligation/WARNING)\": \"15\",\n",
      "    \"License upgrade allowed (right/INFORMATION)\": \"16\",\n",
      "    \"Limitation (limitation/WARNING)\": \"17\",\n",
      "    \"No further restrictions permitted (prohibition/INFORMATION)\": \"18\",\n",
      "    \"Patent grant (other/INFORMATION)\": \"19\",\n",
      "    \"Permissive (right/INFORMATION)\": \"20\",\n",
      "    \"Provide source code location (obligation/WARNING)\": \"21\",\n",
      "    \"Public Domain (other/INFORMATION)\": \"22\",\n",
      "    \"Severe patent retaliation (other/ALARM)\": \"23\",\n",
      "    \"Standard patent retaliation (other/WARNING)\": \"24\",\n",
      "    \"Unclear or Ambiguous (other/ALARM)\": \"25\",\n",
      "    \"Usage notice in advertisement (obligation/INFORMATION)\": \"26\",\n",
      "    \"Use in distributed software (right/INFORMATION)\": \"27\",\n",
      "    \"Written offer to request source code (obligation/WARNING)\": \"28\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: license_name, family, text. If license_name, family, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 972\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 732\n",
      "  Number of trainable parameters = 109,504,541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc77296ca444db0b0b2075a6bee7b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23a29a5c31f48f79dbc7f0aa322bad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-2\\checkpoint-122\n",
      "Configuration saved in ../../model/hp_search\\run-2\\checkpoint-122\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017682256177067757, 'eval_f1_macro': 0.3308952928773526, 'eval_f1_micro': 0.7874659400544959, 'eval_hamming_loss': 0.1014964216005205, 'eval_runtime': 37.7823, 'eval_samples_per_second': 1.403, 'eval_steps_per_second': 0.106, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc01561a63d43829a662b5f3c42b550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-2\\checkpoint-244\n",
      "Configuration saved in ../../model/hp_search\\run-2\\checkpoint-244\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015143858268857002, 'eval_f1_macro': 0.48538409738233323, 'eval_f1_micro': 0.8273195876288659, 'eval_hamming_loss': 0.08718282368249837, 'eval_runtime': 38.6327, 'eval_samples_per_second': 1.372, 'eval_steps_per_second': 0.104, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58cbd59203742deada2f65a28a955fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-2\\checkpoint-366\n",
      "Configuration saved in ../../model/hp_search\\run-2\\checkpoint-366\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014605019241571426, 'eval_f1_macro': 0.4975994869415896, 'eval_f1_micro': 0.8431876606683805, 'eval_hamming_loss': 0.07937540663630449, 'eval_runtime': 38.7796, 'eval_samples_per_second': 1.367, 'eval_steps_per_second': 0.103, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2119ce103d746f8b59ada8a80891551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-2\\checkpoint-488\n",
      "Configuration saved in ../../model/hp_search\\run-2\\checkpoint-488\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014512765221297741, 'eval_f1_macro': 0.575321673417913, 'eval_f1_micro': 0.8498727735368957, 'eval_hamming_loss': 0.07677293428757319, 'eval_runtime': 38.3289, 'eval_samples_per_second': 1.383, 'eval_steps_per_second': 0.104, 'epoch': 4.0}\n",
      "{'loss': 0.013, 'grad_norm': 0.0493619367480278, 'learning_rate': 6.827759225246738e-06, 'epoch': 4.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4d66a961674b0db8aa7bc49b79070a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-2\\checkpoint-610\n",
      "Configuration saved in ../../model/hp_search\\run-2\\checkpoint-610\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014502720907330513, 'eval_f1_macro': 0.5841231937103983, 'eval_f1_micro': 0.8527918781725888, 'eval_hamming_loss': 0.07547169811320754, 'eval_runtime': 38.7081, 'eval_samples_per_second': 1.369, 'eval_steps_per_second': 0.103, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-2\\checkpoint-732\n",
      "Configuration saved in ../../model/hp_search\\run-2\\checkpoint-732\\config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1198f97d23f543658f904a099b93e89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-2\\checkpoint-732\n",
      "Configuration saved in ../../model/hp_search\\run-2\\checkpoint-732\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014404107816517353, 'eval_f1_macro': 0.5857723691226923, 'eval_f1_micro': 0.8567774936061381, 'eval_hamming_loss': 0.07286922576447626, 'eval_runtime': 38.2621, 'eval_samples_per_second': 1.385, 'eval_steps_per_second': 0.105, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[I 2025-03-13 17:39:24,013] Trial 2 finished with value: 1.5154190884933065 and parameters: {'learning_rate': 2.154275755551988e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 6, 'weight_decay': 0.05291984206452107, 'alpha': 0.42034951319231434, 'gamma': 1.819836017561793}. Best is trial 1 with value: 1.5573922398973803.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trial: {'learning_rate': 3.523999264148842e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 12, 'weight_decay': 0.010081010685090833, 'alpha': 0.3670719384605021, 'gamma': 2.1323741129438742}\n",
      "loading configuration file config.json from cache at C:\\Users\\NPARSHO\\.cache\\huggingface\\hub\\models--nlpaueb--legal-bert-base-uncased\\snapshots\\15b570cbf88259610b082a167dacc190124f60f6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Anti-DRM (obligation/WARNING)\",\n",
      "    \"1\": \"Anti-Tivoization (obligation/WARNING)\",\n",
      "    \"10\": \"Display license in binary (obligation/INFORMATION)\",\n",
      "    \"11\": \"Display license in the source (obligation/INFORMATION)\",\n",
      "    \"12\": \"Doing Business with US (other/ALARM)\",\n",
      "    \"13\": \"Endorsement prohibited (prohibition/INFORMATION)\",\n",
      "    \"14\": \"Jurisdiction specific (other/WARNING)\",\n",
      "    \"15\": \"Keep copy of source code available (obligation/WARNING)\",\n",
      "    \"16\": \"License upgrade allowed (right/INFORMATION)\",\n",
      "    \"17\": \"Limitation (limitation/WARNING)\",\n",
      "    \"18\": \"No further restrictions permitted (prohibition/INFORMATION)\",\n",
      "    \"19\": \"Patent grant (other/INFORMATION)\",\n",
      "    \"2\": \"Copyleft (network protective) (obligation/ALARM)\",\n",
      "    \"20\": \"Permissive (right/INFORMATION)\",\n",
      "    \"21\": \"Provide source code location (obligation/WARNING)\",\n",
      "    \"22\": \"Public Domain (other/INFORMATION)\",\n",
      "    \"23\": \"Severe patent retaliation (other/ALARM)\",\n",
      "    \"24\": \"Standard patent retaliation (other/WARNING)\",\n",
      "    \"25\": \"Unclear or Ambiguous (other/ALARM)\",\n",
      "    \"26\": \"Usage notice in advertisement (obligation/INFORMATION)\",\n",
      "    \"27\": \"Use in distributed software (right/INFORMATION)\",\n",
      "    \"28\": \"Written offer to request source code (obligation/WARNING)\",\n",
      "    \"3\": \"Copyleft (strong) (obligation/WARNING)\",\n",
      "    \"4\": \"Copyleft (weak) (obligation/WARNING)\",\n",
      "    \"5\": \"Declare modification in source code (obligation/WARNING)\",\n",
      "    \"6\": \"Deprecated License (other/INFORMATION)\",\n",
      "    \"7\": \"Display acknowledgement message (obligation/WARNING)\",\n",
      "    \"8\": \"Display additional information (obligation/WARNING)\",\n",
      "    \"9\": \"Display copyright notice (obligation/INFORMATION)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Anti-DRM (obligation/WARNING)\": \"0\",\n",
      "    \"Anti-Tivoization (obligation/WARNING)\": \"1\",\n",
      "    \"Copyleft (network protective) (obligation/ALARM)\": \"2\",\n",
      "    \"Copyleft (strong) (obligation/WARNING)\": \"3\",\n",
      "    \"Copyleft (weak) (obligation/WARNING)\": \"4\",\n",
      "    \"Declare modification in source code (obligation/WARNING)\": \"5\",\n",
      "    \"Deprecated License (other/INFORMATION)\": \"6\",\n",
      "    \"Display acknowledgement message (obligation/WARNING)\": \"7\",\n",
      "    \"Display additional information (obligation/WARNING)\": \"8\",\n",
      "    \"Display copyright notice (obligation/INFORMATION)\": \"9\",\n",
      "    \"Display license in binary (obligation/INFORMATION)\": \"10\",\n",
      "    \"Display license in the source (obligation/INFORMATION)\": \"11\",\n",
      "    \"Doing Business with US (other/ALARM)\": \"12\",\n",
      "    \"Endorsement prohibited (prohibition/INFORMATION)\": \"13\",\n",
      "    \"Jurisdiction specific (other/WARNING)\": \"14\",\n",
      "    \"Keep copy of source code available (obligation/WARNING)\": \"15\",\n",
      "    \"License upgrade allowed (right/INFORMATION)\": \"16\",\n",
      "    \"Limitation (limitation/WARNING)\": \"17\",\n",
      "    \"No further restrictions permitted (prohibition/INFORMATION)\": \"18\",\n",
      "    \"Patent grant (other/INFORMATION)\": \"19\",\n",
      "    \"Permissive (right/INFORMATION)\": \"20\",\n",
      "    \"Provide source code location (obligation/WARNING)\": \"21\",\n",
      "    \"Public Domain (other/INFORMATION)\": \"22\",\n",
      "    \"Severe patent retaliation (other/ALARM)\": \"23\",\n",
      "    \"Standard patent retaliation (other/WARNING)\": \"24\",\n",
      "    \"Unclear or Ambiguous (other/ALARM)\": \"25\",\n",
      "    \"Usage notice in advertisement (obligation/INFORMATION)\": \"26\",\n",
      "    \"Use in distributed software (right/INFORMATION)\": \"27\",\n",
      "    \"Written offer to request source code (obligation/WARNING)\": \"28\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 6273.5338, 'train_samples_per_second': 0.93, 'train_steps_per_second': 0.117, 'train_loss': 0.010764774728993901, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: license_name, family, text. If license_name, family, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 972\n",
      "  Num Epochs = 12\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 732\n",
      "  Number of trainable parameters = 109,504,541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84d738f3d8546069c02a5d97245dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51874638c7ac4f7b95f5bb0a050e3850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-61\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-61\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01708749122917652, 'eval_f1_macro': 0.40267470779560843, 'eval_f1_micro': 0.8010680907877169, 'eval_hamming_loss': 0.09694209499024073, 'eval_runtime': 27.8089, 'eval_samples_per_second': 1.906, 'eval_steps_per_second': 0.144, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd3c386ebfb44d4a9c0af81a4d95713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-122\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-122\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01517126802355051, 'eval_f1_macro': 0.5001606421428645, 'eval_f1_micro': 0.8305304010349288, 'eval_hamming_loss': 0.0852309694209499, 'eval_runtime': 27.9213, 'eval_samples_per_second': 1.898, 'eval_steps_per_second': 0.143, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5593a0e5649f4ba4a362df91f7d97226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-183\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-183\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014474988915026188, 'eval_f1_macro': 0.5495273566859381, 'eval_f1_micro': 0.8422391857506362, 'eval_hamming_loss': 0.08067664281067013, 'eval_runtime': 27.8477, 'eval_samples_per_second': 1.903, 'eval_steps_per_second': 0.144, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb85ff279ff84184aa64109e6b1b0a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-244\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-244\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01454697735607624, 'eval_f1_macro': 0.6132603199587112, 'eval_f1_micro': 0.8604060913705583, 'eval_hamming_loss': 0.07156798959011061, 'eval_runtime': 27.9647, 'eval_samples_per_second': 1.895, 'eval_steps_per_second': 0.143, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cdc127cb394ae68932d925efc551af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-305\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-305\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015239044092595577, 'eval_f1_macro': 0.6004720382778966, 'eval_f1_micro': 0.8582375478927203, 'eval_hamming_loss': 0.07221860767729343, 'eval_runtime': 27.7763, 'eval_samples_per_second': 1.908, 'eval_steps_per_second': 0.144, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db3ae05cbe949ab9b372844087c647e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-366\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-366\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015852220356464386, 'eval_f1_macro': 0.6167395495171172, 'eval_f1_micro': 0.8636942675159236, 'eval_hamming_loss': 0.06961613532856213, 'eval_runtime': 27.9214, 'eval_samples_per_second': 1.898, 'eval_steps_per_second': 0.143, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a70584543b6412dbaa2489a926de5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-427\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-427\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01544348057359457, 'eval_f1_macro': 0.6146665874270738, 'eval_f1_micro': 0.8633461047254151, 'eval_hamming_loss': 0.06961613532856213, 'eval_runtime': 27.8965, 'eval_samples_per_second': 1.9, 'eval_steps_per_second': 0.143, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b79c619eaf945a1afaa6ae541c1289d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-488\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-488\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016330905258655548, 'eval_f1_macro': 0.6148682409862591, 'eval_f1_micro': 0.8644501278772379, 'eval_hamming_loss': 0.06896551724137931, 'eval_runtime': 27.8393, 'eval_samples_per_second': 1.904, 'eval_steps_per_second': 0.144, 'epoch': 8.0}\n",
      "{'loss': 0.0083, 'grad_norm': 0.029556605964899063, 'learning_rate': 1.1168959416428025e-05, 'epoch': 8.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b557fade48d4182b2e2c9b936300910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-549\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-549\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016298621892929077, 'eval_f1_macro': 0.612796143135654, 'eval_f1_micro': 0.8611825192802056, 'eval_hamming_loss': 0.07026675341574495, 'eval_runtime': 27.6874, 'eval_samples_per_second': 1.914, 'eval_steps_per_second': 0.144, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ad6770da224d60a8e280ca719b8948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-610\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-610\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01674608327448368, 'eval_f1_macro': 0.6150143322866924, 'eval_f1_micro': 0.8626444159178434, 'eval_hamming_loss': 0.06961613532856213, 'eval_runtime': 27.8481, 'eval_samples_per_second': 1.903, 'eval_steps_per_second': 0.144, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8fea6399094c0f9eb2963fb8f5c4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-671\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-671\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01670306921005249, 'eval_f1_macro': 0.6153622451378055, 'eval_f1_micro': 0.8641025641025641, 'eval_hamming_loss': 0.06896551724137931, 'eval_runtime': 28.0374, 'eval_samples_per_second': 1.89, 'eval_steps_per_second': 0.143, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-732\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-732\\config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: family, license_name, __index_level_0__, text. If family, license_name, __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 53\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ef39dd80864f55b14cd28d3ec5deef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../model/hp_search\\run-3\\checkpoint-732\n",
      "Configuration saved in ../../model/hp_search\\run-3\\checkpoint-732\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01667293719947338, 'eval_f1_macro': 0.6150143322866924, 'eval_f1_micro': 0.8626444159178434, 'eval_hamming_loss': 0.06961613532856213, 'eval_runtime': 26.3921, 'eval_samples_per_second': 2.008, 'eval_steps_per_second': 0.152, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[I 2025-03-14 00:52:07,151] Trial 3 finished with value: 1.5472748835330978 and parameters: {'learning_rate': 3.523999264148842e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 12, 'weight_decay': 0.010081010685090833, 'alpha': 0.3670719384605021, 'gamma': 2.1323741129438742}. Best is trial 1 with value: 1.5573922398973803.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trial: {'learning_rate': 1.8983211874813515e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 13, 'weight_decay': 0.016436174343137766, 'alpha': 0.4312776160305887, 'gamma': 1.6192230403063839}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 25961.6358, 'train_samples_per_second': 0.449, 'train_steps_per_second': 0.028, 'train_loss': 0.006545368439512826, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\NPARSHO\\.cache\\huggingface\\hub\\models--nlpaueb--legal-bert-base-uncased\\snapshots\\15b570cbf88259610b082a167dacc190124f60f6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Anti-DRM (obligation/WARNING)\",\n",
      "    \"1\": \"Anti-Tivoization (obligation/WARNING)\",\n",
      "    \"10\": \"Display license in binary (obligation/INFORMATION)\",\n",
      "    \"11\": \"Display license in the source (obligation/INFORMATION)\",\n",
      "    \"12\": \"Doing Business with US (other/ALARM)\",\n",
      "    \"13\": \"Endorsement prohibited (prohibition/INFORMATION)\",\n",
      "    \"14\": \"Jurisdiction specific (other/WARNING)\",\n",
      "    \"15\": \"Keep copy of source code available (obligation/WARNING)\",\n",
      "    \"16\": \"License upgrade allowed (right/INFORMATION)\",\n",
      "    \"17\": \"Limitation (limitation/WARNING)\",\n",
      "    \"18\": \"No further restrictions permitted (prohibition/INFORMATION)\",\n",
      "    \"19\": \"Patent grant (other/INFORMATION)\",\n",
      "    \"2\": \"Copyleft (network protective) (obligation/ALARM)\",\n",
      "    \"20\": \"Permissive (right/INFORMATION)\",\n",
      "    \"21\": \"Provide source code location (obligation/WARNING)\",\n",
      "    \"22\": \"Public Domain (other/INFORMATION)\",\n",
      "    \"23\": \"Severe patent retaliation (other/ALARM)\",\n",
      "    \"24\": \"Standard patent retaliation (other/WARNING)\",\n",
      "    \"25\": \"Unclear or Ambiguous (other/ALARM)\",\n",
      "    \"26\": \"Usage notice in advertisement (obligation/INFORMATION)\",\n",
      "    \"27\": \"Use in distributed software (right/INFORMATION)\",\n",
      "    \"28\": \"Written offer to request source code (obligation/WARNING)\",\n",
      "    \"3\": \"Copyleft (strong) (obligation/WARNING)\",\n",
      "    \"4\": \"Copyleft (weak) (obligation/WARNING)\",\n",
      "    \"5\": \"Declare modification in source code (obligation/WARNING)\",\n",
      "    \"6\": \"Deprecated License (other/INFORMATION)\",\n",
      "    \"7\": \"Display acknowledgement message (obligation/WARNING)\",\n",
      "    \"8\": \"Display additional information (obligation/WARNING)\",\n",
      "    \"9\": \"Display copyright notice (obligation/INFORMATION)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Anti-DRM (obligation/WARNING)\": \"0\",\n",
      "    \"Anti-Tivoization (obligation/WARNING)\": \"1\",\n",
      "    \"Copyleft (network protective) (obligation/ALARM)\": \"2\",\n",
      "    \"Copyleft (strong) (obligation/WARNING)\": \"3\",\n",
      "    \"Copyleft (weak) (obligation/WARNING)\": \"4\",\n",
      "    \"Declare modification in source code (obligation/WARNING)\": \"5\",\n",
      "    \"Deprecated License (other/INFORMATION)\": \"6\",\n",
      "    \"Display acknowledgement message (obligation/WARNING)\": \"7\",\n",
      "    \"Display additional information (obligation/WARNING)\": \"8\",\n",
      "    \"Display copyright notice (obligation/INFORMATION)\": \"9\",\n",
      "    \"Display license in binary (obligation/INFORMATION)\": \"10\",\n",
      "    \"Display license in the source (obligation/INFORMATION)\": \"11\",\n",
      "    \"Doing Business with US (other/ALARM)\": \"12\",\n",
      "    \"Endorsement prohibited (prohibition/INFORMATION)\": \"13\",\n",
      "    \"Jurisdiction specific (other/WARNING)\": \"14\",\n",
      "    \"Keep copy of source code available (obligation/WARNING)\": \"15\",\n",
      "    \"License upgrade allowed (right/INFORMATION)\": \"16\",\n",
      "    \"Limitation (limitation/WARNING)\": \"17\",\n",
      "    \"No further restrictions permitted (prohibition/INFORMATION)\": \"18\",\n",
      "    \"Patent grant (other/INFORMATION)\": \"19\",\n",
      "    \"Permissive (right/INFORMATION)\": \"20\",\n",
      "    \"Provide source code location (obligation/WARNING)\": \"21\",\n",
      "    \"Public Domain (other/INFORMATION)\": \"22\",\n",
      "    \"Severe patent retaliation (other/ALARM)\": \"23\",\n",
      "    \"Standard patent retaliation (other/WARNING)\": \"24\",\n",
      "    \"Unclear or Ambiguous (other/ALARM)\": \"25\",\n",
      "    \"Usage notice in advertisement (obligation/INFORMATION)\": \"26\",\n",
      "    \"Use in distributed software (right/INFORMATION)\": \"27\",\n",
      "    \"Written offer to request source code (obligation/WARNING)\": \"28\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.48.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: license_name, family, text. If license_name, family, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 972\n",
      "  Num Epochs = 13\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,586\n",
      "  Number of trainable parameters = 109,504,541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490e5779e3a045e495c660a0caec04c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "[W 2025-03-14 00:53:52,046] Trial 4 failed with parameters: {'learning_rate': 1.8983211874813515e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 13, 'weight_decay': 0.016436174343137766, 'alpha': 0.4312776160305887, 'gamma': 1.6192230403063839} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py\", line 249, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "  File \"c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\trainer.py\", line 2163, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\trainer.py\", line 2528, in _inner_training_loop\n",
      "    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-14 00:53:52,052] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21340\\2347930771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Run hyperparameter search with Optuna\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m best_trial = trainer.hyperparameter_search(\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Assuming you're maximizing F1 score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mhp_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhp_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mhyperparameter_search\u001b[1;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[0;32m   3556\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_objective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_compute_objective\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcompute_objective\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcompute_objective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3558\u001b[1;33m         \u001b[0mbest_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3560\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhp_search_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\hyperparameter_search.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mrun_hp_search_optuna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdefault_hp_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py\u001b[0m in \u001b[0;36mrun_hp_search_optuna\u001b[1;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mdirection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdirections\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdirections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_objective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_multi_objective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mbest_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m--> 475\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py\u001b[0m in \u001b[0;36m_objective\u001b[1;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m             \u001b[1;31m# If there hasn't been any evaluation during the training loop.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2161\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m             return inner_training_loop(\n\u001b[0m\u001b[0;32m   2164\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NPARSHO\\AppData\\Local\\anaconda3\\envs\\cuda2\\Lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2526\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2527\u001b[0m                         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2528\u001b[1;33m                         \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2529\u001b[0m                     \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2530\u001b[0m                         \u001b[1;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define your hyperparameter search space\n",
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 15),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.01, 0.1, log=True),\n",
    "        # Focal loss parameters: \n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.25, 0.5),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.5, 3.0)\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../../model/hp_search\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    # These values can be overridden by hyperparameter search\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer with your custom Trainer (using FocalLoss) and model_init\n",
    "trainer = CustomTrainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Run hyperparameter search with Optuna\n",
    "best_trial = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",  # Assuming you're maximizing F1 score\n",
    "    hp_space=hp_space,\n",
    "    n_trials=20  # You can adjust the number of trials\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found:\", best_trial.hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../model/LegalBert\\\\tokenizer_config.json',\n",
       " '../../model/LegalBert\\\\special_tokens_map.json',\n",
       " '../../model/LegalBert\\\\vocab.txt',\n",
       " '../../model/LegalBert\\\\added_tokens.json',\n",
       " '../../model/LegalBert\\\\tokenizer.json')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"../../model/LegalBert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
